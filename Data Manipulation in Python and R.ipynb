{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both R and Python are incredibly good tools to manipulate your data and their integration is becoming [increasingly important](http://www.r-bloggers.com/r-6-in-ieee-2015-top-programming-languages-rising-3-places/). The latest tool for data manipulation in R is [Dplyr](https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html) whilst Python relies on [Pandas](http://pandas.pydata.org/). \n",
    "\n",
    "In this blog post I'll show you how to manipulate your dataframes using both libraries highlighting their major advantages/disadvantages.\n",
    "\n",
    "## Theory first\n",
    "\n",
    "Data Frames are basically tables. [Codd, E.F.](https://en.wikipedia.org/wiki/Edgar_F._Codd) in 1970 defined [Relational algebra](https://en.wikipedia.org/wiki/Relational_algebra) as the basic the theory to work on relational tables. It defines the following operations:\n",
    "\n",
    "* Projection (π)\n",
    "* Selection (σ)\n",
    "* Rename (ρ)\n",
    "* Set operators (union, difference, cartesian product)\n",
    "* Natural join (⋈)\n",
    "\n",
    "SQL dialects also added the following\n",
    "\n",
    "* Aggregations\n",
    "* Group by operations\n",
    "\n",
    "Why we care? People redefined these basic operations over and over in the last 40 years starting with SQL until today latest query languages. Using this framework will give us a general basic perspective on the data manipulation in the two frameworks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands on\n",
    "I will use the nycflights13 dataset used to introduce [dplyr](https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html) to present the functions. If you are interested you can download this entire blog post as an <a href=\"http://www.alfredo.motta.name/wp-content/uploads/2015/07/Data-Manipulation-in-Python-and-R.ipynb_.zip\">IPython notebook</a>. Let's initialise our environment first:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Load the R magic command\n",
    "%load_ext rpy2.ipython\n",
    "from rpy2.robjects import pandas2ri\n",
    "\n",
    "# numpy available as np\n",
    "# pyplot available as ply\n",
    "%pylab\n",
    "\n",
    "from pandas import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/rpy2/robjects/functions.py:106: UserWarning: \n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "  res = super(Function, self).__call__(*new_args, **new_kwargs)\n",
      "/Library/Python/2.7/site-packages/rpy2/robjects/functions.py:106: UserWarning: The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "  res = super(Function, self).__call__(*new_args, **new_kwargs)\n",
      "/Library/Python/2.7/site-packages/rpy2/robjects/functions.py:106: UserWarning: The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "  res = super(Function, self).__call__(*new_args, **new_kwargs)\n"
     ]
    }
   ],
   "source": [
    "%%R -o flights\n",
    "#sink(type=\"output\")\n",
    "sink(\"/dev/null\")\n",
    "library(\"dplyr\");\n",
    "library(nycflights13);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flights = pandas2ri.ri2py(flights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data summary\n",
    "\n",
    "In both libraries it is possible to quickly print a quick summary of your dataframe. Pandas has an object oriented approach and you can invoke `head()`, `tail()` and `describe()` directly on your dataframe object. R has a procedural approach and its functions take a dataframe as the first input.\n",
    "\n",
    "\n",
    "| Python            | R                       |\n",
    "|-------------------|-------------------------|\n",
    "|`df.head()`     |`head(df)`            |\n",
    "|`df.tail()`     |`tail(df)`            |\n",
    "|`df.describe()` |`summary(df)`         |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Python\n",
    "\n",
    "flights.head();\n",
    "flights.tail();\n",
    "flights.describe();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%R head(flights);\n",
    "%R tail(flights);\n",
    "%R summary(flights);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pandas in order to select multiple rows you need to use the `[]` operator with the element-wise operators like `&` and `|`. If you don't use the element-wise operators you will get the `ValueError: The truth value of a Series is ambiguous.` error. Another solution is to install the [numexpr](https://github.com/pydata/numexpr) package and use the `query()` function.\n",
    "\n",
    "`dplyr` instead provides the `filter()` function. Combined with the pipe operator `%>%` the code is incredibly readable in my opinion. Notice how repeating the dataframe variable in the boolean expression is not needed in this case.\n",
    "\n",
    "\n",
    "| Python            | R                                       |\n",
    "|-------------------|-----------------------------------------|\n",
    "|`df[bool expr with element-wise operators]`     |`df %>% filter(bool expr)` |\n",
    "|`df.query('bool expr')`     | |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Python\n",
    "\n",
    "# Simple filtering\n",
    "flights[flights.month <= 3];\n",
    "\n",
    "# Filtering with element-wise operators\n",
    "flights[(flights.month >= 3) & (flights.month <= 6)];\n",
    "\n",
    "# with numexpr\n",
    "flights.query('month >= 3 & month <= 6');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%R flights %>% filter(month >= 3 & month <= 6);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection\n",
    "You can use the projection operation to extract one (or more) columns from a dataframe. In Python you pass an array with the columns you are interested in to the DataFrame object. In dplyr the projection function is called select, inspired by SQL.\n",
    "\n",
    "\n",
    "| Python            | R                                       |\n",
    "|-------------------|-----------------------------------------|\n",
    "|`df[['col_1', 'col_2']]`     |`df %>% select(col_1, col_2)` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Python\n",
    "flights[['year', 'month']];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%R flights %>% select(month, year);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename\n",
    "\n",
    "The rename operation is used to simply rename a column of your dataframe keeping the content intact. In pandas you use the [rename](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.rename.html) function and you provide a dictionary. In R you use a comma separated list of assignments.\n",
    "\n",
    "| Python            | R                                       |\n",
    "|-------------------|-----------------------------------------|\n",
    "|`df.rename(columns={'col_name': 'col_new_name'})`     |`df %>% rename(col_new_name = col_name)` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Python\n",
    "flights.rename(columns={'month': 'TheMonth'});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%R flights %>% rename(TheMonth = month);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Union\n",
    "The relational algebra uses set union, set difference, and Cartesian product from set theory, with the extra constraint that tables must be \"compatible\", i.e. they must have the same columns.\n",
    "\n",
    "You can use the union in Pandas using the [`concat()`](http://pandas.pydata.org/pandas-docs/stable/merging.html) operation. You need to take some extra care for indexes though and for that I'll forward you [to the docs](http://pandas.pydata.org/pandas-docs/stable/merging.html#concatenating-objects). \n",
    "\n",
    "In R you rely on the [`bind_rows`](http://rpackages.ianhowson.com/cran/dplyr/man/bind.html) operator.\n",
    "\n",
    "| Python            | R                                       |\n",
    "|-------------------|-----------------------------------------|\n",
    "|`concat([df_1, df_2]);`     |`rbind_list(df_1, df_2)` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Python\n",
    "\n",
    "df_1 = flights.query('dep_time == 518');\n",
    "df_2 = flights.query('dep_time == 517');\n",
    "concat([df_1, df_2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "sink(\"/dev/null\")\n",
    "df_1 = filter(flights, dep_time == 517);\n",
    "df_2 = filter(flights, dep_time == 518);\n",
    "bind_rows(df_1, df_2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference\n",
    "To the best of my knowledge there is no set difference operator in Python. In order to achieve the result we must rely on the select operator.\n",
    "\n",
    "In dplyr there is a native operator `setdiff` that does exactly what we expect.\n",
    "\n",
    "| Python            | R                                       |\n",
    "|-------------------|-----------------------------------------|\n",
    "|`set_a[~set_a.column.isin(set_b.column)]`     |`set_a %>% setdiff(set_b)` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Python\n",
    "\n",
    "set_a = flights.query('dep_time == 517 | dep_time == 518');\n",
    "set_b = flights.query('dep_time == 518 | dep_time == 519');\n",
    "\n",
    "selection = ~set_a.dep_time.isin(set_b.dep_time);\n",
    "set_a[selection];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "#sink(type=\"output\")\n",
    "#sink(\"/dev/null\")\n",
    "set_a = filter(flights, dep_time == 517 | dep_time == 518);\n",
    "set_b = filter(flights, dep_time == 518 | dep_time == 519);\n",
    "set_a %>% setdiff(set_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cartesian product\n",
    "\n",
    "You can use the cartesian product to combine two tables with a disjoint set of columns. In practice this is not a very common operation and as a result both libraries lack a pure cartesian product (in favour of the way more common `join` operator).\n",
    "\n",
    "A simple trick to overcome this limitation is to create a temporary column first, perform the join and finally remove the temporary column. This can be done both in Python and R using the `merge()` and `full_join` methods.\n",
    "\n",
    "| Python            | R                                       |\n",
    "|-------------------|-----------------------------------------|\n",
    "|`merge(...) with tmp column`     |`full_join(...) with tmp column` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Python\n",
    "\n",
    "df_1 = DataFrame({\n",
    "        'name': ['Jack', 'Mario', 'Luigi']\n",
    "    });\n",
    "df_2 = DataFrame({\n",
    "        'surname': ['Rossi', 'Verdi', 'Reacher']\n",
    "    });\n",
    "\n",
    "df_1['tmp'] = np.nan;\n",
    "df_2['tmp'] = np.nan;\n",
    "\n",
    "merge(df_1, df_2, on='tmp').drop('tmp', axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "#sink(type=\"output\")\n",
    "sink(\"/dev/null\")\n",
    "df_1 = data.frame(\n",
    "    name=c('Jack', 'Mario', 'Luigi'),\n",
    "    stringsAsFactors=FALSE)\n",
    "\n",
    "df_2 = data.frame(\n",
    "    surname=c('Rossi', 'Verdi', 'Reacher'), \n",
    "    stringsAsFactors=FALSE)\n",
    "\n",
    "df_1$tmp = NA\n",
    "df_2$tmp = NA\n",
    "\n",
    "full_join(df_1, df_2, by=\"tmp\") %>% select(-tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Join\n",
    "If you are used to SQL you are definitely aware of what a join operation is. Given two dataframe R and S the result of the natural join is the set of all combinations of tuples in R and S that are equal on their common attribute names.\n",
    "\n",
    "In Python you can rely on the very powerful [merge](http://pandas.pydata.org/pandas-docs/stable/merging.html#brief-primer-on-merge-methods-relational-algebra) command.  \n",
    "In R Dplyr you can use the [full_join](https://cran.r-project.org/web/packages/dplyr/dplyr.pdf) command.\n",
    "\n",
    "| Python            | R                                       |\n",
    "|-------------------|-----------------------------------------|\n",
    "|`merge(..., on=\"key\", how=\"outer\")`     |`full_join(..., by=\"key\")` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Python\n",
    "df_1 = DataFrame({\n",
    "        'name': ['Jack', 'Mario', 'Luigi'],\n",
    "        'department_id' : [30, 31, 31]\n",
    "    });\n",
    "df_2 = DataFrame({\n",
    "        'department_name': ['Sales', 'Product', 'Finance'],\n",
    "        'department_id' : [30, 31, 32]\n",
    "    });\n",
    "\n",
    "merge(df_1, df_2, on=\"department_id\", how=\"outer\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "#sink(type=\"output\")\n",
    "sink(\"/dev/null\")\n",
    "\n",
    "df_1 = data.frame(\n",
    "    name=c('Jack', 'Mario', 'Luigi'),\n",
    "    department_id=c(30, 31, 31),\n",
    "    stringsAsFactors=FALSE)\n",
    "\n",
    "df_2 = data.frame(\n",
    "    department_name=c('Sales', 'Product', 'Finance'), \n",
    "    department_id=c(30, 31, 32),\n",
    "    stringsAsFactors=FALSE)\n",
    "\n",
    "full_join(df_1, df_2, by=\"department_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregations\n",
    "An aggregate function is a function that takes the values of a certain column to form a single value of more significant meaning. Typical aggregate functions available in the most common SQL dialects include Average(), Count(), Maximum(), Median(), Minimum(), Mode(), Sum().\n",
    "\n",
    "Both R and Python dataframes provides methods to extract this information. In this case I would say that Python handle missing values default better, whilst on R we have to provide `na.rm = TRUE`.  \n",
    "\n",
    "| Python            | R                                       |\n",
    "|-------------------|-----------------------------------------|\n",
    "|`df.<column>.mean()`    |`summarise(df, test=mean(<column>, na.rm = TRUE))` |\n",
    "|`df.<column>.median()`  |`summarise(df, test=median(<column>, na.rm = TRUE))` |\n",
    "|`df.<column>.std()`     |`summarise(df, test=sd(<column>, na.rm = TRUE))` |\n",
    "|`df.<column>.var()`     |`summarise(df, test=var(<column>, na.rm = TRUE))` |\n",
    "|`df.<column>.min()`     |`summarise(df, test=min(<column>, na.rm = TRUE))` |\n",
    "|`df.<column>.max()`     |`summarise(df, test=max(<column>, na.rm = TRUE))` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Python\n",
    "\n",
    "flights.dep_time.mean();\n",
    "flights.dep_time.median();\n",
    "flights.dep_time.std();\n",
    "flights.dep_time.var();\n",
    "flights.dep_time.min();\n",
    "flights.dep_time.max();\n",
    "flights.dep_time.mean();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "#sink(type=\"output\")\n",
    "sink(\"/dev/null\")\n",
    "\n",
    "summarise(flights, test=mean(dep_time, na.rm = TRUE))\n",
    "summarise(flights, test=median(dep_time, na.rm = TRUE))\n",
    "summarise(flights, test=min(dep_time, na.rm = TRUE))\n",
    "summarise(flights, test=max(dep_time, na.rm = TRUE))\n",
    "summarise(flights, test=sd(dep_time, na.rm = TRUE))\n",
    "summarise(flights, test=var(dep_time, na.rm = TRUE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group by\n",
    "\n",
    "Aggregations become useful especially when used in conjunction with the group by operator. This way we are able to compute statistics for a number of group subsets with just one command.\n",
    "\n",
    "Both Python and R provides the function to run a group by. \n",
    "\n",
    "| Python            | R                                       |\n",
    "|-------------------|-----------------------------------------|\n",
    "|`df.groupby('<column>')`    |`df %>% group_by(<column>)` |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Python\n",
    "\n",
    "# For any given day compute the mean of the flights departure time\n",
    "flights.groupby('day').dep_time.mean();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "#sink(type=\"output\")\n",
    "sink(\"/dev/null\")\n",
    "\n",
    "flights %>% \n",
    "    group_by(day) %>% \n",
    "    summarise(dep_time_mean=mean(dep_time, na.rm = TRUE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think the Pandas and Dplyr paradigms are very different between each other. \n",
    "\n",
    "Pandas is more focused on object orientation and good defaults. Indexes are a first class entity and as a result some operations that you expect to be simple are instead quite difficult to grasp.\n",
    "\n",
    "Conversely Dplyr is procedural. I love the pipe operator and manipulating my data feels incredibly smooth. The only sad note is that sometimes functions defaults are not that great. I haven't tested the speed in this blog post but I assume that since indexes are hidden in Dplyr the speed is probably much lower in general.\n",
    "\n",
    "In conclusion I feel like Dplyr and R are the perfect tool for some early exploration of the data. But if you are serious about the code you are producing you should probably switch to Python to productionise your data analysis.\n",
    "\n",
    "Let me know your approach in the comments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
